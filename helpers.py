import sqlite3
import datetime
import json
import queue
import threading

# å…¨å±€æ—¥å¿—é˜Ÿåˆ—ï¼Œç”¨äºå‘å‰ç«¯å¹¿æ’­æ—¥å¿—
log_queue = queue.Queue(maxsize=1000)

def broadcast_log_to_frontend(log_message):
    """å‘å‰ç«¯å¹¿æ’­æ—¥å¿—æ¶ˆæ¯"""
    try:
        log_data = {
            'timestamp': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3],
            'message': log_message
        }
        # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œç§»é™¤æœ€è€çš„æ¶ˆæ¯
        if log_queue.full():
            try:
                log_queue.get_nowait()
            except queue.Empty:
                pass
        log_queue.put_nowait(log_data)
    except queue.Full:
        pass  # å¦‚æœé˜Ÿåˆ—æ»¡äº†å°±å¿½ç•¥

def log_model_request(model_name, prompt_type, input_summary=""):
    """è®°å½•æ¨¡å‹è¯·æ±‚æ—¥å¿—"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_message = f"[{timestamp}] ğŸ¤– MODEL REQUEST | {model_name} | {prompt_type} | Input: {input_summary}"
    print(log_message)
    broadcast_log_to_frontend(log_message)

def log_model_response(model_name, prompt_type, success=True, output_summary="", error_msg=""):
    """è®°å½•æ¨¡å‹å“åº”æ—¥å¿—"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    status = "âœ… SUCCESS" if success else "âŒ ERROR"
    if success:
        log_message = f"[{timestamp}] ğŸ¤– MODEL RESPONSE | {model_name} | {prompt_type} | {status} | Output: {output_summary}"
    else:
        log_message = f"[{timestamp}] ğŸ¤– MODEL RESPONSE | {model_name} | {prompt_type} | {status} | Error: {error_msg}"
    print(log_message)
    broadcast_log_to_frontend(log_message)

def log_processing_step(step_name, status="START", details="", item_count=None):
    """è®°å½•å¤„ç†æ­¥éª¤æ—¥å¿—"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    if status == "START":
        count_info = f"({item_count} items)" if item_count else ""
        log_message = f"[{timestamp}] âš™ï¸  PROCESSING | {step_name} | ğŸš€ {status} {count_info} | {details}"
    elif status == "COMPLETE":
        count_info = f"({item_count} completed)" if item_count else ""
        log_message = f"[{timestamp}] âš™ï¸  PROCESSING | {step_name} | âœ… {status} {count_info} | {details}"
    elif status == "ERROR":
        log_message = f"[{timestamp}] âš™ï¸  PROCESSING | {step_name} | âŒ {status} | {details}"
    else:
        log_message = f"[{timestamp}] âš™ï¸  PROCESSING | {step_name} | â„¹ï¸  {status} | {details}"
    print(log_message)
    broadcast_log_to_frontend(log_message)

def log_batch_item(batch_name, item_index, total_items, item_name, success=True, details=""):
    """è®°å½•æ‰¹é‡å¤„ç†ä¸­å•ä¸ªé¡¹ç›®çš„æ—¥å¿—"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    status = "âœ…" if success else "âŒ"
    progress = f"({item_index + 1}/{total_items})"
    log_message = f"[{timestamp}] ğŸ“¦ BATCH | {batch_name} | {status} {progress} | {item_name} | {details}"
    print(log_message)
    broadcast_log_to_frontend(log_message)

def log_desensitization(data_type, name_or_title, success=True, error_msg=""):
    """è®°å½•è„±æ•å¤„ç†æ—¥å¿—"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    status = "âœ… SUCCESS" if success else "âŒ ERROR"
    if success:
        log_message = f"[{timestamp}] ğŸ”’ DESENSITIZATION | {data_type} | {status} | {name_or_title}"
    else:
        log_message = f"[{timestamp}] ğŸ”’ DESENSITIZATION | {data_type} | {status} | {name_or_title} | Error: {error_msg}"
    print(log_message)
    broadcast_log_to_frontend(log_message)

def diagnose_json_error(json_text, error_msg):
    """è¯Šæ–­JSONé”™è¯¯å¹¶æä¾›è¯¦ç»†ä¿¡æ¯"""
    lines = json_text.split('\n')
    total_lines = len(lines)
    
    # æå–é”™è¯¯ä½ç½®ä¿¡æ¯
    import re
    line_match = re.search(r'line (\d+)', error_msg)
    char_match = re.search(r'char (\d+)', error_msg)
    
    if line_match:
        error_line = int(line_match.group(1))
        context = []
        
        # æ˜¾ç¤ºé”™è¯¯è¡Œå‰åçš„ä¸Šä¸‹æ–‡
        start_line = max(1, error_line - 2)
        end_line = min(total_lines, error_line + 2)
        
        for i in range(start_line - 1, end_line):
            prefix = ">>> " if i == error_line - 1 else "    "
            context.append(f"{prefix}Line {i+1}: {lines[i]}")
        
        context_str = "\n".join(context)
        return f"JSON Error Context:\n{context_str}\nTotal lines: {total_lines}"
    
    return f"JSON Error: {error_msg}\nJSON preview: {json_text[:200]}..."

def get_db_connection():
    """Establishes a connection to the SQLite database."""
    conn = sqlite3.connect('talent_match.db', check_same_thread=False)
    conn.row_factory = sqlite3.Row
    return conn

def check_and_migrate_db():
    """Checks for table existence and adds them if they don't exist."""
    log_processing_step("DATABASE_MIGRATION", "START", "Checking database schema")
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # List of all tables that should exist
    required_tables = {'resumes', 'job_descriptions', 'facilitation_results'}
    
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    existing_tables = {row[0] for row in cursor.fetchall()}
    
    missing_tables = required_tables - existing_tables
    
    if missing_tables:
        log_processing_step("DATABASE_MIGRATION", "PROGRESS", f"Missing tables detected: {', '.join(missing_tables)}")
        with open('schema.sql') as f:
            conn.executescript(f.read())
        log_processing_step("DATABASE_MIGRATION", "COMPLETE", "Database schema applied successfully")
    else:
        log_processing_step("DATABASE_MIGRATION", "COMPLETE", "Database schema is up-to-date")
    
    conn.close()

def get_prompt(filename):
    """Loads a prompt from the prompts directory."""
    try:
        with open(f'prompts/{filename}', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return None 

def get_resume_and_jd_info(resume_id, jd_id):
    """
    ä»æ•°æ®åº“ä¸­è·å–ç®€å†å’ŒJDçš„å®Œæ•´ä¿¡æ¯
    
    Args:
        resume_id (int): ç®€å†ID
        jd_id (int): èŒä½æè¿°ID
    
    Returns:
        tuple: (resume_info, jd_info) åŒ…å«å®Œæ•´ä¿¡æ¯çš„å­—å…¸ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å› (None, None)
    """
    log_processing_step("GET_RESUME_JD_INFO", "START", f"Fetching Resume ID: {resume_id}, JD ID: {jd_id}")
    
    conn = get_db_connection()
    
    try:
        # è·å–ç®€å†ä¿¡æ¯
        resume = conn.execute('SELECT * FROM resumes WHERE id = ?', (resume_id,)).fetchone()
        if not resume:
            log_processing_step("GET_RESUME_JD_INFO", "ERROR", f"Resume ID {resume_id} not found")
            return None, None
        
        # è·å–JDä¿¡æ¯
        jd = conn.execute('SELECT * FROM job_descriptions WHERE id = ?', (jd_id,)).fetchone()
        if not jd:
            log_processing_step("GET_RESUME_JD_INFO", "ERROR", f"JD ID {jd_id} not found")
            return None, None
        
        # æ„å»ºç®€å†ä¿¡æ¯å­—å…¸
        resume_info = {
            'id': resume['id'],
            'name': resume['name'],
            'email': resume['email'],
            'phone': resume['phone'],
            'skills': resume['skills'],
            'summary': resume['summary'],
            'experience': json.loads(resume['experience_json']) if resume['experience_json'] else [],
            'education': json.loads(resume['education_json']) if resume['education_json'] else [],
            'publications': json.loads(resume['publications_json']) if resume['publications_json'] else [],
            'projects': json.loads(resume['projects_json']) if resume['projects_json'] else [],
            'desensitized_data': json.loads(resume['desensitized_json']) if resume['desensitized_json'] else None,
            'created_at': resume['created_at']
        }
        
        # æ„å»ºJDä¿¡æ¯å­—å…¸
        jd_info = {
            'id': jd['id'],
            'title': jd['title'],
            'company': jd['company'],
            'location': jd['location'],
            'salary': jd['salary'],
            'requirements': jd['requirements'],
            'description': jd['description'],
            'benefits': jd['benefits'],
            'desensitized_data': json.loads(jd['desensitized_json']) if jd['desensitized_json'] else None,
            'created_at': jd['created_at']
        }
        
        log_processing_step("GET_RESUME_JD_INFO", "COMPLETE", 
                          f"Retrieved {resume_info['name']} -> {jd_info['title']} @ {jd_info['company']}")
        
        return resume_info, jd_info
        
    except Exception as e:
        log_processing_step("GET_RESUME_JD_INFO", "ERROR", f"Database error: {str(e)}")
        return None, None
    finally:
        conn.close() 

def find_jd_by_id_or_title(jd_id: int = None, title: str = None) -> str:
    """
    æ ¹æ®èŒä½IDæˆ–èŒä½åç§°ä»æ•°æ®åº“ä¸­æŸ¥è¯¢èŒä½æè¿°(JD)ã€‚
    ä¼˜å…ˆä½¿ç”¨ ID æŸ¥è¯¢ã€‚å¦‚æœä¸¤è€…éƒ½æœªæä¾›ï¼Œåˆ™è¿”å›é”™è¯¯ã€‚
    
    Args:
        jd_id (int, optional): èŒä½çš„æ•°æ®åº“IDã€‚
        title (str, optional): èŒä½çš„æ ‡é¢˜ã€‚
        
    Returns:
        str: ä¸€ä¸ªJSONå­—ç¬¦ä¸²ï¼ŒåŒ…å«æŸ¥è¯¢åˆ°çš„JDä¿¡æ¯æˆ–é”™è¯¯ä¿¡æ¯ã€‚
    """
    if not jd_id and not title:
        return json.dumps({"status": "error", "message": "å¿…é¡»æä¾›èŒä½IDæˆ–èŒä½åç§°ã€‚"})

    conn = get_db_connection()
    try:
        if jd_id:
            log_processing_step("JD_TOOL_SEARCH", "START", f"é€šè¿‡IDæŸ¥è¯¢JD: {jd_id}")
            query = 'SELECT * FROM job_descriptions WHERE id = ?'
            params = (jd_id,)
        else:
            log_processing_step("JD_TOOL_SEARCH", "START", f"é€šè¿‡æ ‡é¢˜æŸ¥è¯¢JD: {title}")
            # ä½¿ç”¨LIKEè¿›è¡Œæ¨¡ç³ŠåŒ¹é…ï¼Œå¹¶ä¼˜å…ˆé€‰æ‹©æœ€æ–°çš„ä¸€ä¸ª
            query = 'SELECT * FROM job_descriptions WHERE title LIKE ? ORDER BY created_at DESC LIMIT 1'
            params = (f'%{title}%',)

        jd = conn.execute(query, params).fetchone()

        if jd:
            jd_dict = dict(jd)
            log_processing_step("JD_TOOL_SEARCH", "COMPLETE", f"æˆåŠŸæ‰¾åˆ°JD: {jd_dict['title']} (ID: {jd_dict['id']})")
            return json.dumps({"status": "success", "data": jd_dict}, ensure_ascii=False, indent=2)
        else:
            log_processing_step("JD_TOOL_SEARCH", "COMPLETE", "æœªæ‰¾åˆ°å¯¹åº”çš„JDã€‚")
            return json.dumps({"status": "not_found", "message": "æœªæ‰¾åˆ°å¯¹åº”çš„èŒä½æè¿°ã€‚"})
    except Exception as e:
        log_processing_step("JD_TOOL_SEARCH", "ERROR", f"æ•°æ®åº“æŸ¥è¯¢JDæ—¶å‡ºé”™: {str(e)}")
        return json.dumps({"status": "error", "message": f"æ•°æ®åº“æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"})
    finally:
        conn.close() 