import json
import os
from openai import OpenAI
from helpers import log_model_request, log_model_response, log_processing_step, get_prompt
import re
from datetime import datetime

# Initialize OpenAI client
openai_client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
    base_url="http://47.93.181.123:4000",
)

class RecruiterAgent:
    def __init__(self, resume_info, jd_info, company_profile):
        """
        åˆå§‹åŒ–æ‹›è˜æ–¹agent
        
        Args:
            resume_info: è„±æ•çš„ç®€å†ä¿¡æ¯
            jd_info: å®Œæ•´çš„èŒä½ä¿¡æ¯
            company_profile: ä¼ä¸šæ‹›è˜ç”»åƒ
        """
        self.resume_info = resume_info  # è¿™æ˜¯è„±æ•ç‰ˆæœ¬
        self.jd_info = jd_info
        self.company_profile = company_profile
        self.conversation_history = []  # å­˜å‚¨å®Œæ•´å¯¹è¯å†å²ï¼ˆåŒ…æ‹¬planningï¼‰
        self.chat_history = []  # å­˜å‚¨ç»™å¯¹æ–¹çœ‹çš„chattingå†å²
        self.decision_made = False
        self.final_decision = "UNCERTAIN"
        self.chat_rounds = 0  # è®°å½•å¯¹è¯è½®æ•°
        
    def get_system_prompt(self):
        """è·å–æ‹›è˜æ–¹agentçš„ç³»ç»Ÿæç¤º"""
        prompt = get_prompt('recruiter_agent_system.txt')
        if not prompt:
            # å¦‚æœæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤º
            return """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ‹›è˜ä»£ç†ï¼Œä»£è¡¨ä¼ä¸šçš„åˆ©ç›Šè¿›è¡Œäººæ‰æ‹›è˜æ’®åˆã€‚è¯·ç”¨JSONæ ¼å¼å›å¤ï¼ŒåŒ…å«typeã€reasoningã€payloadå­—æ®µã€‚"""
        
        # æ›¿æ¢ä¼ä¸šç”»åƒå ä½ç¬¦
        if self.company_profile:
            profile_text = json.dumps(self.company_profile, ensure_ascii=False, indent=2)
            prompt = prompt.replace('{COMPANY_PROFILE_PLACEHOLDER}', profile_text)
        else:
            prompt = prompt.replace('{COMPANY_PROFILE_PLACEHOLDER}', 'æš‚æ— ç”»åƒä¿¡æ¯')
        
        return prompt

    def respond(self, history=None):
        """
        æ ¸å¿ƒæ–¹æ³•ï¼Œæ ¹æ®ç”¨æˆ·æ¶ˆæ¯å’Œå†å²è®°å½•ç”Ÿæˆå›åº”
        """
        system_prompt = get_prompt('recruiter_agent_system.txt')
        messages = [{"role": "system", "content": system_prompt}]

        # å¦‚æœæ²¡æœ‰å†å²è®°å½•ï¼Œæ„å»ºåˆå§‹ä¸Šä¸‹æ–‡
        if not history:
            initial_user_prompt = f"""ä»¥ä¸‹æ˜¯ç›¸å…³ä¿¡æ¯ï¼š

èŒä½ä¿¡æ¯ï¼š
{json.dumps(self.jd_info, ensure_ascii=False, indent=2)}

å€™é€‰äººç®€å†ä¿¡æ¯ï¼ˆè„±æ•ç‰ˆï¼‰ï¼š
{json.dumps(self.resume_info, ensure_ascii=False, indent=2)}

ä¼ä¸šæ‹›è˜ç”»åƒï¼š
{json.dumps(self.company_profile, ensure_ascii=False, indent=2)}
"""
            messages.append({"role": "user", "content": initial_user_prompt})
            
            # åˆå§‹å¯åŠ¨æŒ‡ä»¤
            messages.append({"role": "user", "content": "è¯·å¼€å§‹è¯„ä¼°è¿™ä¸ªå€™é€‰äººï¼Œå¹¶ä¸å€™é€‰äººä»£ç†è¿›è¡Œæ²Ÿé€šã€‚è¯·å…ˆplanningï¼Œç„¶åå‘é€chattingæ¶ˆæ¯ã€‚"})
        else:
            # å¦‚æœæœ‰å†å²è®°å½•ï¼Œç›´æ¥ä½¿ç”¨
            messages.extend(history)
        
        # å¢åŠ é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # éµå¾ª LOGGING_GUIDE.md æ ¼å¼è®°å½•æ¨¡å‹è¯·æ±‚
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                model_name = "bedrock-claude-4-sonnet"
                task_type = "RECRUITER_AGENT_CHAT"
                
                print(f"[{timestamp}] ğŸ¤– MODEL REQUEST | {model_name} | {task_type} | Input: {json.dumps(messages, ensure_ascii=False, indent=2)}")
                
                response = openai_client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    temperature=1,
                    max_tokens=2000
                )
                
                response_content = response.choices[0].message.content

                # å¢åŠ å¯¹ç©ºå“åº”çš„æ£€æŸ¥å’Œé‡è¯•é€»è¾‘
                if not response_content:
                    if attempt < max_retries - 1:
                        log_processing_step("RECRUITER_AGENT", "RETRY", f"Empty response on attempt {attempt + 1}, retrying...")
                        continue
                    else:
                        log_model_response("bedrock-claude-4-sonnet", "RECRUITER_AGENT_RESPONSE", success=False, error_msg="Empty response from model after all retries")
                        return {
                            "type": "chatting",
                            "reasoning": f"æ¨¡å‹åœ¨{max_retries}æ¬¡å°è¯•åä»è¿”å›ç©ºå“åº”ï¼Œä½¿ç”¨é»˜è®¤å›å¤",
                            "payload": "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚"
                        }

                try:
                    # è§£ææ¨¡å‹è¿”å›çš„JSONå­—ç¬¦ä¸²
                    parsed_response = json.loads(response_content)
                    response_type = parsed_response.get("type")
                    reasoning = parsed_response.get("reasoning")
                    payload = parsed_response.get("payload")

                    if not response_type or not payload:
                        raise ValueError("JSONå“åº”ç¼ºå°‘'type'æˆ–'payload'å­—æ®µ")

                except json.JSONDecodeError as e:
                    # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶ä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„ã€å®‰å…¨çš„å›å¤
                    error_message = f"JSONè§£æå¤±è´¥: {e}"
                    log_processing_step("RECRUITER_AGENT", "DEBUG", f"JSON decode error: {e}")
                    log_model_response("bedrock-claude-4-sonnet", "RECRUITER_AGENT_RESPONSE", success=False, error_msg=error_message)

                    # è¿”å›ä¸€ä¸ªå®‰å…¨çš„ã€é€šç”¨çš„èŠå¤©æ¶ˆæ¯
                    return {
                        "type": "chatting",
                        "reasoning": f"JSONè§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å›å¤",
                        "payload": "æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†ä¿¡æ¯æ—¶é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
                    }

                # æ ¹æ®å“åº”ç±»å‹æ›´æ–°å†…éƒ¨çŠ¶æ€
                self.conversation_history.append({
                    "sender": "recruiter",
                    "type": response_type,
                    "reasoning": reasoning,
                    "content": payload,
                    "timestamp": __import__('datetime').datetime.now().isoformat()
                })
                
                # å¤„ç†ä¸åŒç±»å‹çš„å›å¤
                if response_type == "planning":
                    # planningä¸éœ€è¦é¢å¤–å¤„ç†ï¼Œå·²è®°å½•åˆ°å†å²ä¸­
                    pass
                elif response_type == "chatting":
                    # chattingæ¶ˆæ¯éœ€è¦è®°å½•åˆ°å¯¹æ–¹å¯è§çš„å†å²ä¸­
                    self.chat_rounds += 1
                    self.chat_history.append({
                        "sender": "recruiter",
                        "content": payload,
                        "round": self.chat_rounds,
                        "timestamp": __import__('datetime').datetime.now().isoformat()
                    })
                elif response_type == "decision":
                    # å¤„ç†å†³ç­–
                    self.decision_made = True
                    if payload == "åŒæ„":
                        self.final_decision = "SUITABLE"
                    elif payload == "æ‹’ç»":
                        self.final_decision = "UNSUITABLE"
                    else:
                        self.final_decision = "UNKNOWN"
                
                log_model_response("bedrock-claude-4-sonnet", "RECRUITER_AGENT_RESPONSE", success=True,
                                  output_summary=f"Generated {response_type} message, decision_made: {self.decision_made}")
                log_processing_step("RECRUITER_AGENT", "COMPLETE", 
                                   f"Recruiter agent generated {response_type} message")
                
                return {
                    "type": response_type,
                    "reasoning": reasoning,
                    "payload": payload
                }
                
            except Exception as e:
                if attempt < max_retries - 1:
                    log_processing_step("RECRUITER_AGENT", "RETRY", f"Error on attempt {attempt + 1}: {str(e)}, retrying...")
                    continue
                else:
                    # æœ€åä¸€æ¬¡å°è¯•ä¹Ÿå¤±è´¥äº†
                    log_model_response("bedrock-claude-4-sonnet", "RECRUITER_AGENT_RESPONSE", success=False, 
                                      error_msg=f"All {max_retries} attempts failed: {str(e)}")
                    
                    # è¿”å›é”™è¯¯æ ¼å¼
                    return {
                        "type": "chatting",
                        "reasoning": f"å¤šæ¬¡é‡è¯•åä»ç„¶å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å›å¤",
                        "payload": f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼ˆ{str(e)}ï¼‰ï¼Œè¯·ç¨åé‡è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚",
                        "error": True
                    }
    
    def get_conversation_history(self):
        """è·å–å®Œæ•´å¯¹è¯å†å²ï¼ˆåŒ…æ‹¬planningï¼‰"""
        return self.conversation_history
    
    def get_chat_history(self):
        """è·å–å¯¹æ–¹å¯è§çš„chattingå†å²"""
        return self.chat_history
    
    def get_final_decision(self):
        """è·å–æœ€ç»ˆå†³ç­–"""
        return self.final_decision
    
    def has_reached_decision(self):
        """æ£€æŸ¥æ˜¯å¦å·²åšå‡ºæœ€ç»ˆå†³ç­–"""
        return self.decision_made
    
    def get_chat_rounds(self):
        """è·å–å¯¹è¯è½®æ•°"""
        return self.chat_rounds 